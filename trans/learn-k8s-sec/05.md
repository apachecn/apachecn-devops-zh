# *第五章*:配置库本内斯安全边界

安全边界分隔安全域，其中一组实体共享相同的安全关注点和访问级别，而信任边界是程序执行和数据改变信任级别的分界线。安全边界中的控件确保在没有适当验证的情况下，在边界之间移动的执行不会提升信任级别。当数据或执行在没有适当控制的情况下在安全边界之间移动时，安全漏洞就会出现。

在本章中，我们将讨论安全和信任边界的重要性。我们将首先关注介绍，以澄清安全和信任边界之间的任何混淆。然后，我们将遍历 Kubernetes 生态系统中的安全域和安全边界。最后，我们将了解一些 Kubernetes 特性，这些特性增强了部署在 Kubernetes 中的应用程序的安全边界。

您应该理解安全域和安全边界的概念，也应该理解基于底层容器技术围绕 Kubernetes 构建的安全边界，以及内置的安全功能，如 PodSecurityPolicy 和 NetworkPolicy。

我们将在本章中讨论以下主题:

*   安全边界介绍
*   安全边界与信任边界
*   Kubernetes 安全域
*   作为安全边界的 Kubernetes 实体
*   系统层的安全边界
*   网络层的安全边界

# 安全边界介绍

安全边界存在于数据层、网络层和系统层。安全界限取决于信息技术部门或基础设施团队使用的技术。例如，公司使用虚拟机来管理其应用程序—虚拟机管理程序是虚拟机的安全边界。虚拟机管理程序确保虚拟机中运行的代码不会从虚拟机中逸出或影响物理节点。当公司开始采用微服务并使用编排器来管理他们的应用程序时，容器就是安全边界之一。但是，与虚拟机管理程序相比，容器并不提供强有力的安全边界，也不是为了。容器在应用层实施限制，但不能阻止攻击者从内核层绕过这些限制。

在网络层，传统上，防火墙为应用程序提供强大的安全边界。在微服务架构中，Kubernetes 中的 Pods 可以与其他人进行通信。网络策略用于限制 Pods 和服务之间的通信。

数据层的安全边界是众所周知的。内核将对系统或 bin 目录的写访问权限限制为仅根用户或系统用户，这是数据层安全边界的一个简单示例。在容器化的环境中，chroot 防止容器篡改其他容器的文件系统。Kubernetes 以一种可以在网络层和系统层强制实施强安全边界的方式来重构应用程序部署。

# 安全边界与信任边界

安全边界和信任边界经常被用作同义词。虽然相似，但这两个术语之间存在着的细微差别。一个**信任边界**是系统改变其信任级别的地方。执行信任边界是指令需要不同特权才能运行的地方。例如，在`/bin`中执行代码的数据库服务器就是一个跨越信任边界的执行示例。类似地，数据信任边界是数据在具有不同信任级别的实体之间移动的地方。终端用户插入到可信数据库中的数据是数据跨越信任边界的一个例子。

**安全边界**是不同安全域之间的分界点，而安全域是同一访问级别内的一组实体。例如，在传统的 web 架构中，面向用户的应用程序是安全域的一部分，而内部网络是不同安全域的一部分。安全边界有与之相关的访问控制。把信任边界想象成一堵墙，把安全边界想象成围绕着墙的栅栏。

确定生态系统中的安全和信任边界非常重要。它有助于确保在越过边界之前对指令和数据进行适当的验证。在 Kubernetes 中，组件和对象跨越不同的安全边界。当攻击者越过安全边界时，理解这些边界以制定风险缓解计划是很重要的。CVE-2018-1002105 是因跨越信任边界的验证缺失而导致的攻击的主要例子；API 服务器中的代理请求处理允许未经身份验证的用户获得群集的管理员权限。同样，CVE-2018-18264 允许用户跳过仪表板上的身份验证过程，以允许未经身份验证的用户访问敏感的群集信息。

现在我们来看看不同的 Kubernetes 安全域名 ins。

# Kubernetes 安全域

Kubernetes 集群可以大致分为三个安全域:

*   **库本内特主组件**:库本内特主组件定义了库本内特生态系统的控制平面。主组件负责集群平稳运行所需的决策，如调度。主组件包括`kube-apiserver`、`etcd`、`kube-controller`管理器、DNS 服务器和`kube-scheduler`。Kubernetes 主组件中的漏洞会危及整个 Kubernetes 集群。
*   **Kubernetes 工作组件** : Kubernetes 工作组件部署在每个工作节点上，确保 Pods 和容器运行良好。Kubernetes 工作组件使用授权和 TLS 隧道与主组件通信。集群可以在工作组件受损的情况下运行。它类似于环境中的流氓节点，一旦被识别，就可以从集群中删除。
*   **Kubernetes 对象** : Kubernetes 对象是表示集群状态的持久实体:部署的应用程序、卷和命名空间。Kubernetes 对象包括 Pods、服务、卷和名称空间。这些由开发人员或 DevOps 部署。对象规范为对象定义了额外的安全边界:定义一个带有安全上下文的 Pod、与其他 Pod 通信的网络规则等等。

高级安全域部门应该帮助您专注于关键资产。记住这一点，我们将开始研究 Kubernetes 实体和为它们建立的安全边界。

# 作为安全边界的 Kubernetes 实体

在 Kubernetes 集群中，您与之交互的 Kubernetes 实体(对象和组件)有自己的内置安全边界。安全边界源自实体的设计或实现。理解构建在它们内部或周围的安全界限非常重要:

*   **容器**:容器是 Kubernetes 集群中的基本组件。容器使用 cgroups、Linux 名称空间、AppArmor 配置文件和运行在容器内的应用程序的 seccomp 配置文件为应用程序提供最小隔离。
*   **豆荚**:豆荚是一个或多个容器的集合。与容器相比，Pods 隔离了更多的资源，例如网络和 IPC。安全上下文、网络策略和 PodSecurityPolicy 等功能在 pod 级别工作，以确保更高级别的隔离。
*   **节点**:库本内特斯的节点也是安全边界。可以使用`nodeSelectors`指定 Pods 在特定节点上运行。内核和虚拟机管理程序对节点上运行的吊舱实施安全控制。像 AppArmor 和 SELinux 这样的特性以及其他主机强化机制可以帮助提高安全性。
*   **集群**:集群是主节点和工作节点上的荚、容器和组件的集合。一个集群提供了强大的安全边界。在一个集群内运行的 Pods 和容器在网络和系统层与其他集群隔离。
*   **命名空间**:命名空间是隔离 pods 和服务的虚拟集群。LimitRanger 准入控制器在名称空间级别应用来控制资源利用和拒绝服务攻击。网络策略可以应用于命名空间级别。
*   **Kubernetes API 服务器**:Kubernetes API 服务器与所有 Kubernetes 组件交互，包括`etcd`、`controller-manager`和`kubelet`，这是集群管理员用来配置集群的。它调解与主组件的通信，因此集群管理员不必直接与集群组件交互。

我们在 [*第 3 章*](03.html#_idTextAnchor091)*威胁建模*中讨论了三种不同的威胁参与者:特权攻击者、内部攻击者和最终用户。这些威胁行为者也可能与前面的库本内特实体进行交互。我们将看到攻击者面临这些实体的安全边界:

*   **终端用户**:终端用户或者与入口交互，或者直接与节点上的开放端口交互。对于最终用户来说，节点、Pods、`kube-apiserver`和外部防火墙保护集群组件不受损害。
*   **内部攻击者**:内部攻击者可以访问 Pods 和容器。由`kube-apiserver`实施的名称空间和访问控制防止这些攻击者升级特权或危害集群。网络政策和 RBAC 控制可以防止横向移动。
*   **特权攻击者** : `kube-apiserver`是保护主组件免受特权攻击者危害的唯一安全边界。如果特权攻击者妥协`kube-apiserver`，游戏就结束了。

在本节中，我们从用户的角度来看安全边界，并向您展示了安全边界是如何在 Kubernetes 生态系统中构建的。接下来，让我们从微服务的角度来看系统层的安全边界。

# 系统层的安全边界

微服务在 Pods 内部运行，Pods 计划在集群中的工作节点上运行。在前面的章节中，我们已经强调了容器是一个被分配了专用 Linux 名称空间的进程。容器或 Pod 消耗了工作节点提供的所有必要资源。因此，从系统的角度理解安全边界以及如何加强它是很重要的。在本节中，我们将一起讨论基于 Linux 名称空间和 Linux 功能构建的微服务的安全边界。

## Linux 命名空间作为安全边界

Linux 命名空间是 Linux 内核的一个特性，用于出于隔离目的对资源进行分区。通过分配名称空间，一组进程可以看到一组资源，而另一组进程可以看到另一组资源。我们已经在 [*第 2 章*](02.html#_idTextAnchor049)*Kubernetes Networking*中介绍了 Linux 名称空间。默认情况下，每个 Pod 都有自己的网络命名空间和 IPC 命名空间。同一 pod 中的每个容器都有自己的 PID 名称空间，因此一个容器不知道同一 Pod 中运行的其他容器。同样，一个 Pod 不知道同一工作节点中存在其他 Pod。

总的来说，从安全角度来看，默认设置为微服务提供了相当好的隔离。但是，允许在 Kubernetes 工作负载中配置主机命名空间设置，更具体地说，在 Pod 规范中。启用这些设置后，微服务使用主机级命名空间:

*   **主机网络**:Pod 使用主机的网络命名空间。
*   **主机 IPC**:Pod 使用主机的 IPC 命名空间。
*   **主机 PID**:Pod 使用主机的 PID 命名空间。
*   **共享进程名称空间**:同一个 Pod 中的容器将共享一个 PID 名称空间。

当您尝试将工作负载配置为使用主机名称空间时，一定要问自己一个问题:为什么必须这样做？当使用主机名称空间时，pods 完全了解同一个工作节点中其他 pods 的活动，但这也取决于分配给容器的 Linux 功能。总的来说，事实是，您解除了其他微服务的安全界限。让我举一个简单的例子。这是容器内可见的进程列表:

```
root@nginx-2:/# ps aux
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root           1  0.1  0.0  32648  5256 ?        Ss   23:47   0:00 nginx: master process nginx -g daemon off;
nginx          6  0.0  0.0  33104  2348 ?        S    23:47   0:00 nginx: worker process
root           7  0.0  0.0  18192  3248 pts/0    Ss   23:48   0:00 bash
root          13  0.0  0.0  36636  2816 pts/0    R+   23:48   0:00 ps aux
```

如您所见，在`nginx`容器内，从容器中只能看到`nginx`流程和`bash`流程。这个`nginx` pod 不使用主机 PID 命名空间。让我们看看如果 pod 使用主机 PID 命名空间会发生什么:

```
root@gke-demo-cluster-default-pool-c9e3510c-tfgh:/# ps axu
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root           1  0.2  0.0  99660  7596 ?        Ss   22:54   0:10 /usr/lib/systemd/systemd noresume noswap cros_efi
root          20  0.0  0.0      0     0 ?        I<   22:54   0:00 [netns]
root          71  0.0  0.0      0     0 ?        I    22:54   0:01 [kworker/u4:2]
root         101  0.0  0.1  28288  9536 ?        Ss   22:54   0:01 /usr/lib/systemd/systemd-journald
201          293  0.2  0.0  13688  4068 ?        Ss   22:54   0:07 /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile 
274          297  0.0  0.0  22520  4196 ?        Ss   22:54   0:00 /usr/lib/systemd/systemd-networkd
root         455  0.0  0.0      0     0 ?        I    22:54   0:00 [kworker/0:3]
root        1155  0.0  0.0   9540  3324 ?        Ss   22:54   0:00 bash /home/kubernetes/bin/health-monitor.sh container-runtime
root        1356  4.4  1.5 1396748 118236 ?      Ssl  22:56   2:30 /home/kubernetes/bin/kubelet --v=2 --cloud-provider=gce --experimental
root        1635  0.0  0.0 773444  6012 ?        Sl   22:56   0:00 containerd-shim -namespace moby -workdir /var/lib/containerd/io.contai
root        1660  0.1  0.4 417260 36292 ?        Ssl  22:56   0:03 kube-proxy --master=https://35.226.122.194 --kubeconfig=/var/lib/kube-
root        2019  0.0  0.1 107744  7872 ?        Ssl  22:56   0:00 /ip-masq-agent --masq-chain=IP-MASQ --nomasq-all-reserved-ranges
root        2171  0.0  0.0  16224  5020 ?        Ss   22:57   0:00 sshd: gke-1a5c3c1c4d5b7d80adbc [priv]
root        3203  0.0  0.0   1024     4 ?        Ss   22:57   0:00 /pause
root        5489  1.3  0.4  48008 34236 ?        Sl   22:57   0:43 calico-node -felix
root        6988  0.0  0.0  32648  5248 ?        Ss   23:01   0:00 nginx: master process nginx -g daemon off;
nginx       7009  0.0  0.0  33104  2584 ?        S    23:01   0:00 nginx: worker process
```

前面的输出显示了工作节点中从`nginx`容器运行的进程。这些流程中有系统流程、`sshd`、`kubelet`、`kube-proxy`等等。除了从使用主机 PID 命名空间的 Pod，您还可以向其他微服务的进程发送信号，例如`SIGKILL`来终止一个进程。

## Linux 功能作为安全边界

Linux 能力是从传统 Linux 权限检查演变而来的概念:特权和非特权。特权进程绕过所有内核权限检查。然后，Linux 将与 Linux 超级用户相关的特权划分为不同的单元——Linux 功能。有网络相关功能，如`CAP_NET_ADMIN`、`CAP_NET_BIND_SERVICE`、`CAP_NET_BROADCAST`、`CAP_NET_RAW`。还有审计相关能力:`CAP_AUDIT_CONTROL`、`CAP_AUDIT_READ`、`CAP_AUDIT_WRITE`。当然，还有一个类似管理的功能:`CAP_SYS_ADMIN`。

如 [*第四章*](04.html#_idTextAnchor108)*所述，在 Kubernetes* 中应用最小特权原则，可以为一个 pod 中的容器配置 Linux 功能。默认情况下，以下是分配给 Kubernetes 集群中容器的功能列表:

*   `CAP_SETPCAP`
*   `CAP_MKNOD`
*   `CAP_AUDIT_WRITE`
*   `CAP_CHOWN`
*   `CAP_NET_RAW`
*   `CAP_DAC_OVERRIDE`
*   `CAP_FOWNER`
*   `CAP_FSETID`
*   `CAP_KILL`
*   `CAP_SETGID`
*   `CAP_SETUID`
*   `CAP_NET_BIND_SERVICE`
*   `CAP_SYS_CHROOT`
*   `CAP_SETFCAP`

对于大多数微服务来说，这些能力应该足以执行它们的日常任务。您应该删除所有功能，只添加必需的功能。与主机名称空间类似，授予额外的功能可能会解除其他微服务的安全边界。以下是在容器中运行`tcpdump`命令时的输出示例:

```
root@gke-demo-cluster-default-pool-c9e3510c-tfgh:/# tcpdump -i cali01fb9a4e4b4 -v
tcpdump: listening on cali01fb9a4e4b4, link-type EN10MB (Ethernet), capture size 262144 bytes
23:18:36.604766 IP (tos 0x0, ttl 64, id 27472, offset 0, flags [DF], proto UDP (17), length 86)
    10.56.1.14.37059 > 10.60.0.10.domain: 35359+ A? www.google.com.default.svc.cluster.local. (58)
23:18:36.604817 IP (tos 0x0, ttl 64, id 27473, offset 0, flags [DF], proto UDP (17), length 86)
    10.56.1.14.37059 > 10.60.0.10.domain: 35789+ AAAA? www.google.com.default.svc.cluster.local. (58)
23:18:36.606864 IP (tos 0x0, ttl 62, id 8294, offset 0, flags [DF], proto UDP (17), length 179)
    10.60.0.10.domain > 10.56.1.14.37059: 35789 NXDomain 0/1/0 (151)
23:18:36.606959 IP (tos 0x0, ttl 62, id 8295, offset 0, flags [DF], proto UDP (17), length 179)
    10.60.0.10.domain > 10.56.1.14.37059: 35359 NXDomain 0/1/0 (151)
23:18:36.607013 IP (tos 0x0, ttl 64, id 27474, offset 0, flags [DF], proto UDP (17), length 78)
    10.56.1.14.59177 > 10.60.0.10.domain: 7489+ A? www.google.com.svc.cluster.local. (50)
23:18:36.607053 IP (tos 0x0, ttl 64, id 27475, offset 0, flags [DF], proto UDP (17), length 78)
    10.56.1.14.59177 > 10.60.0.10.domain: 7915+ AAAA? www.google.com.svc.cluster.local. (50)
```

前面的输出显示，在一个容器内，有`tcpdump`在监听网络接口`cali01fb9a4e4b4`，它是为另一个吊舱的网络通信而创建的。有了主机网络名称空间和`CAP_NET_ADMIN`授权，您可以嗅探来自容器内整个工作节点的网络流量。一般来说，授予容器的功能越少，其他微服务的边界就越安全。

## 在系统层包装安全边界

专用的 Linux 命名空间和默认分配给容器或 Pod 的有限的 Linux 功能为微服务建立了良好的安全边界。但是，仍然允许用户配置主机名称空间或向工作负载添加额外的 Linux 功能。这将解除在同一工作节点上运行的其他微服务的安全边界。你这样做应该非常小心。通常，监控工具或安全工具需要访问主机名称空间才能完成其监控工作或检测工作。并且强烈建议使用`PodSecurityPolicy`来限制主机名称空间的使用以及额外的功能，从而加强微服务的安全边界。

接下来，让我们从微服务的角度来看一下 netw 工作层中设置的安全边界。

# 网络层的安全边界

Kubernetes 网络策略为允许相互通信的不同 Pods 组定义了规则。在前一章中，我们简要讨论了 Kubernetes 网络策略的出口规则，该规则可用于实施微服务的最小特权原则。在本节中，我们将详细介绍 Kubernetes 网络策略，并将重点介绍入口规则。我们将展示网络策略的入口规则如何帮助建立微服务之间的信任边界。

## 网络策略

如前一章所述，根据网络模型要求，集群内部的 Pods 可以相互通信。但是，从安全角度来看，您可能希望将您的微服务限制为仅被少数服务访问。我们如何在 Kubernetes 实现这一目标？让我们快速浏览一下以下 Kubernetes 网络策略示例:

```
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-network-policy
  namespace: default
spec:
  podSelector:
    matchLabels:
      role: db
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - ipBlock:
        cidr: 172.17.0.0/16
        except:
        - 172.17.1.0/24
    - namespaceSelector:
        matchLabels:
          project: myproject
    - podSelector:
        matchLabels:
          role: frontend
    ports:
    - protocol: TCP
      port: 6379
  egress:
  - to:
    - ipBlock:
        cidr: 10.0.0.0/24
    ports:
    - protocol: TCP
      port: 5978
```

`NetworkPolicy`政策被命名为`test-network-policy`。这里列出了网络策略规范中值得一提的几个关键属性，以帮助您了解限制是什么:

*   `podSelector`:基于 Pod 标签的策略适用的一组 Pod。
*   `Ingress`: Ingress rules that apply to the Pods specified in the top-level `podSelector`. The different elements under `Ingress` are discussed as follows:

    - `ipBlock`:允许与入口源通信的 IP CIDR 范围

    - `namespaceSelector`:基于名称空间标签允许作为入口源的名称空间

    - `podSelector`:根据 Pod 标签允许作为入口源的 Pod

    - `ports`:应该允许所有吊舱与之通信的端口和协议

*   `egress`: Egress rules that apply to the Pods specified in the top-level `podSelector`. The different elements under `Ingress` are discussed as follows:

    - `ipBlock`:允许作为出口目的地通信的 IP CIDR 范围

    - `namespaceSelector`:基于名称空间标签允许作为出口目的地的名称空间

    - `podSelector`:根据 Pod 标签允许作为出口目的地的 Pod

    - `ports`:所有 Pods 都应该被允许与之通信的目标端口和协议

通常，`ipBlock`用于指定在 Kubernetes 集群中允许微服务交互的外部 IP 块，而名称空间选择器和 Pod 选择器用于限制同一 Kubernetes 集群中微服务之间的网络通信。

为了从网络方面加强微服务的信任边界，您可能希望从外部指定允许的`ipBlock`或者从特定的名称空间指定允许的微服务。下面是另一个通过使用`namespaceSelector`和`podSelector`来限制某些 Pods 和名称空间的入口源的示例:

```
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-good
spec:
  podSelector:
    matchLabels:
      app: web
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          from: good
      podSelector:
        matchLabels:
          from: good
```

注意`podSelector`属性前面没有`-`。这意味着入口源只能是标签为的 pods，名称空间中的标签为`from: good`的 pods。该网络策略通过默认命名空间中的标签`app: web`保护 Pods:

![Figure 5.1 – Network policy restricting incoming traffic by Pod and namespace labels ](image/B15566_05_001.jpg)

图 5.1–通过 Pod 和命名空间标签限制传入流量的网络策略

在上图中，`good`命名空间有标签`from: good`，而`bad`命名空间有标签`from: bad`。它说明了只有名称空间中标签为`from: good`的 Pods 才能访问默认名称空间中的`nginx-web`服务。其他 Pods，无论它们是来自`good`命名空间但没有标签`from: good`还是来自其他命名空间，都不能让访问默认命名空间中的`nginx-web`服务。

# 总结

在本章中，我们讨论了安全边界的重要性。了解 Kubernetes 生态系统中的安全域和安全边界有助于管理员了解攻击的爆炸半径，并制定缓解策略来限制攻击事件造成的损害。了解 Kubernetes 实体是强化安全边界的起点。下一步是了解使用 Linux 名称空间和功能构建到系统层的安全边界。最后但并非最不重要的一点是，理解网络策略的力量对于将安全细分构建到微服务中也至关重要。

完成本章后，您应该掌握安全域和安全边界的概念。您还应该知道安全域、Kubernetes 中的公共实体，以及在 Kubernetes 实体内部或周围构建的安全边界。您应该知道使用内置安全功能(如 PodSecurityPolicy 和 NetworkPolicy)来强化安全边界和仔细配置工作负载的安全上下文的重要性。

在下一章中，我们将讨论如何保护 Kubernetes 组件。特别是，有一些配置细节需要注意。

# 问题

1.  Kubernetes 中有哪些安全域？
2.  你与哪些常见的 Kubernetes 实体交互？
3.  如何限制 Kubernetes 用户访问特定命名空间中的对象？
4.  启用 hostPID 对 pod 意味着什么？
5.  尝试配置一个网络策略来保护您的服务，该策略只允许特定的 Pods 作为入口源。

# 进一步参考

*   Kubernetes 网络策略:[https://kubernetes . io/docs/concepts/service-networking/network-policies/](https://kubernetes.io/docs/concepts/services-networking/network-policies/)
*   CVE-2018-18264:[https://groups . Google . com/forum/#！search in/kubrines-announce/CVE-2018-18264% 7 csort:date/kubrines-announce/ybrff 5 nmvfi/郭 60 kilcaaj](https://groups.google.com/forum/#!searchin/kubernetes-announce/CVE-2018-18264%7Csort:date/kubernetes-announce/yBrFf5nmvfI/gUO60KIlCAAJ)
*   CVE-2018-1002105:[https://groups . Google . com/forum/#！主题/立方结构-公告/GVllWCg6L88](https://groups.google.com/forum/#!topic/kubernetes-announce/GVllWCg6L88)